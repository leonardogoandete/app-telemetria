# App Telemetria - Plataforma de Auto-Scaling Preditivo

## ğŸ“‹ VisÃ£o Geral

Esta Ã© uma plataforma completa de telemetria com auto-scaling preditivo usando KEDA e PredictKube, que inclui:

- **AplicaÃ§Ã£o de telemetria** com mÃ©tricas Prometheus
- **Auto-scaling preditivo** com KEDA 2.15.1 e PredictKube
- **Monitoramento** com Prometheus e Grafana
- **Testes de carga** com K6
- **SimulaÃ§Ã£o de dados histÃ³ricos** para treinamento do modelo preditivo

## ğŸ› ï¸ PrÃ©-requisitos

### 1. MicroK8s
```bash
# Instalar MicroK8s
sudo snap install microk8s --classic

# Adicionar usuÃ¡rio ao grupo microk8s
sudo usermod -a -G microk8s $USER
sudo chown -f -R $USER ~/.kube

# Reiniciar sessÃ£o ou executar:
newgrp microk8s

# Habilitar addons necessÃ¡rios
microk8s enable dns
microk8s enable storage
microk8s enable metallb  # Configure com range de IPs da sua rede

# Configurar kubectl
microk8s kubectl config view --raw > ~/.kube/config
```

### 2. Helm
```bash
# Instalar Helm
curl https://baltocdn.com/helm/signing.asc | gpg --dearmor | sudo tee /usr/share/keyrings/helm.gpg > /dev/null
sudo apt-get install apt-transport-https --yes
echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/helm.gpg] https://baltocdn.com/helm/stable/debian/ all main" | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list
sudo apt-get update
sudo apt-get install helm
```

### 3. Docker
```bash
# Instalar Docker (se nÃ£o estiver instalado)
sudo apt-get update
sudo apt-get install docker.io
sudo usermod -aG docker $USER
# Reiniciar sessÃ£o apÃ³s adicionar ao grupo
```

## ğŸš€ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 1. Instalar KEDA 2.15.1 via Helm

```bash
# Adicionar repositÃ³rio do KEDA
helm repo add kedacore https://kedacore.github.io/charts
helm repo update

# Criar namespace para KEDA
kubectl create namespace keda-system

# Instalar KEDA 2.15.1
helm install keda kedacore/keda \
  --version 2.15.1 \
  --namespace keda-system \
  --set prometheus.metricServer.enabled=true \
  --set prometheus.operator.enabled=true

# Verificar instalaÃ§Ã£o
kubectl get pods -n keda-system
```

### 2. Habilitar MÃ©tricas do KEDA para Prometheus

```bash
# Habilitar mÃ©tricas do Prometheus no KEDA operator
kubectl patch deployment keda-operator -n keda-system --type='json' -p='[
  {
    "op": "replace", 
    "path": "/spec/template/spec/containers/0/args", 
    "value": [
      "--zap-log-level=info",
      "--zap-encoder=console", 
      "--zap-time-encoding=rfc3339",
      "--cert-dir=/certs",
      "--enable-cert-rotation=true",
      "--cert-secret-name=kedaorg-certs",
      "--operator-service-name=keda-operator",
      "--metrics-server-service-name=keda-operator-metrics-apiserver",
      "--webhooks-service-name=keda-admission-webhooks",
      "--k8s-cluster-name=kubernetes-default",
      "--k8s-cluster-domain=cluster.local",
      "--enable-prometheus-metrics=true",
      "--metrics-bind-address=0.0.0.0:8080"
    ]
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/ports/-",
    "value": {
      "containerPort": 8080,
      "name": "http-metrics",
      "protocol": "TCP"
    }
  }
]'

# Aguardar o rollout
kubectl rollout status deployment/keda-operator -n keda-system
```

### 3. Configurar PredictKube (Opcional)

```bash
# Criar secret para PredictKube (substitua pelos valores corretos)
kubectl create secret generic predictkube-secrets \
  --from-literal=api-key="sua-chave-api" \
  --from-literal=endpoint="https://api.predictkube.com"
```

## ğŸ“¦ Deploy da AplicaÃ§Ã£o

### 1. Deploy AutomÃ¡tico
```bash
# Tornar o script executÃ¡vel
chmod +x deploy.sh

# Executar deploy
./deploy.sh
```

### 2. Deploy Manual
```bash
# Build da imagem
cd src
docker build -t app-telemetria:latest .
cd ..

# Importar imagem para MicroK8s
docker save app-telemetria:latest | microk8s ctr image import -

# Aplicar manifestos
kubectl apply -k k8s/

# Aguardar pods ficarem prontos
kubectl wait --for=condition=ready pod -l app=app-a --timeout=300s
kubectl wait --for=condition=ready pod -l app=prometheus --timeout=300s
kubectl wait --for=condition=ready pod -l app=grafana --timeout=300s
```

## ğŸŒ Acesso aos ServiÃ§os

### NodePort (Acesso Externo)
- **AplicaÃ§Ã£o**: http://192.168.0.100:30080
- **MÃ©tricas da AplicaÃ§Ã£o**: http://192.168.0.100:30081  
- **Prometheus**: http://192.168.0.100:30090
- **Grafana**: http://192.168.0.100:30300
  - UsuÃ¡rio: `admin`
  - Senha: `admin123`

### Port-Forward (Acesso Local)
```bash
# AplicaÃ§Ã£o
kubectl port-forward svc/app-a-service 8000:8000

# Prometheus  
kubectl port-forward svc/prometheus-service 9090:9090

# Grafana
kubectl port-forward svc/grafana-service 3000:3000
```

## ğŸ“Š Monitoramento e MÃ©tricas

### MÃ©tricas DisponÃ­veis

#### AplicaÃ§Ã£o (app-a)
- `app_requests_total` - Total de requisiÃ§Ãµes
- `app_requests_historical_*` - Dados histÃ³ricos simulados (7 dias)

#### KEDA
- `keda_internal_metricsservice_grpc_client_handled_total` - RequisiÃ§Ãµes gRPC
- `keda_internal_metricsservice_grpc_client_handling_seconds` - LatÃªncia gRPC
- MÃ©tricas de scaling e performance

### Dashboard Grafana

O Grafana inclui um dashboard prÃ©-configurado com:
- **Taxa de requisiÃ§Ãµes atual**
- **Total de requisiÃ§Ãµes**
- **Threshold do PredictKube** 
- **Pods ativos**
- **TendÃªncia de requisiÃ§Ãµes com thresholds**
- **Atividade de scaling**
- **DistribuiÃ§Ã£o por endpoint**
- **Dados histÃ³ricos simulados**
- **MÃ©tricas do KEDA**

## ğŸ§ª Testes de Carga

### K6 Load Testing
```bash
# Instalar K6
sudo apt-get update
sudo apt-get install k6

# Executar teste bÃ¡sico
k6 run src/load-test.js

# Executar teste realÃ­stico (com padrÃµes de fim de semana/semana)
k6 run src/realistic-load.js
```

### PadrÃµes de Teste
- **load-test.js**: Teste bÃ¡sico com carga crescente
- **realistic-load.js**: PadrÃµes realÃ­sticos com variaÃ§Ã£o semanal/fim de semana

## âš™ï¸ ConfiguraÃ§Ã£o do Auto-Scaling

### PredictKube ScaledObject
```yaml
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: app-a-predictkube
spec:
  scaleTargetRef:
    name: app-a
  minReplicaCount: 1
  maxReplicaCount: 10
  triggers:
  - type: predictkube
    metadata:
      # Threshold para scaling (requests/sec)
      threshold: "10"
      activationThreshold: "5"
      # Janela de histÃ³rico para previsÃ£o
      historyTimeWindow: "7d"
      # Horizonte de previsÃ£o
      predictionHorizon: "2h"
```

### Thresholds Configurados
- **Threshold**: 10 req/s (inicia scaling)
- **Activation Threshold**: 5 req/s (ativa o scaler)
- **Min Replicas**: 1
- **Max Replicas**: 10

## ğŸ”§ Troubleshooting

### Verificar Status dos Pods
```bash
kubectl get pods -A
kubectl describe pod <pod-name>
kubectl logs <pod-name> -f
```

### Verificar KEDA
```bash
kubectl get scaledobjects
kubectl describe scaledobject app-a-predictkube
kubectl logs -n keda-system -l app=keda-operator -f
```

### Verificar MÃ©tricas
```bash
# Testar mÃ©tricas da aplicaÃ§Ã£o
curl http://192.168.0.100:30081/metrics

# Verificar targets no Prometheus
curl http://192.168.0.100:30090/api/v1/targets
```

### Logs dos Componentes
```bash
# AplicaÃ§Ã£o
kubectl logs -l app=app-a -f

# Prometheus
kubectl logs -l app=prometheus -f

# Grafana
kubectl logs -l app=grafana -f

# KEDA
kubectl logs -n keda-system -l app=keda-operator -f
```

## ğŸ—‘ï¸ Limpeza

```bash
# Remover aplicaÃ§Ã£o
kubectl delete -k k8s/

# Remover KEDA
helm uninstall keda -n keda-system
kubectl delete namespace keda-system

# Remover imagem do MicroK8s
microk8s ctr images rm app-telemetria:latest
```

## ğŸ“ Estrutura do Projeto

```
app-telemetria/
â”œâ”€â”€ src/                          # CÃ³digo da aplicaÃ§Ã£o
â”‚   â”œâ”€â”€ app.py                   # AplicaÃ§Ã£o Flask
â”‚   â”œâ”€â”€ Dockerfile               # Build da imagem
â”‚   â”œâ”€â”€ requirements.txt         # DependÃªncias Python
â”‚   â”œâ”€â”€ load-test.js            # Teste K6 bÃ¡sico
â”‚   â””â”€â”€ realistic-load.js       # Teste K6 realÃ­stico
â”œâ”€â”€ k8s/                         # Manifestos Kubernetes
â”‚   â”œâ”€â”€ app-a-deployment.yaml   # Deploy da aplicaÃ§Ã£o
â”‚   â”œâ”€â”€ app-a-service.yaml      # ServiÃ§o da aplicaÃ§Ã£o
â”‚   â”œâ”€â”€ app-a-scaledobject.yaml # Auto-scaling KEDA/PredictKube
â”‚   â”œâ”€â”€ prometheus-*.yaml       # ConfiguraÃ§Ã£o Prometheus
â”‚   â”œâ”€â”€ grafana-*.yaml          # ConfiguraÃ§Ã£o Grafana
â”‚   â””â”€â”€ kustomization.yaml      # Kustomize
â”œâ”€â”€ deploy.sh                    # Script de deploy automÃ¡tico
â””â”€â”€ README.md                    # Esta documentaÃ§Ã£o
```

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request
- Encadeamento de chamadas entre mÃºltiplos serviÃ§os
- ConfiguraÃ§Ã£o completa de Docker e Docker Compose para execuÃ§Ã£o fÃ¡cil

Este cÃ³digo serve como ponto de partida para uma aula/workshop sobre instrumentaÃ§Ã£o de aplicaÃ§Ãµes com OpenTelemetry. O cÃ³digo base estÃ¡ pronto para ter instrumentaÃ§Ã£o adicionada.

## Estrutura do Projeto

```
.
â”œâ”€â”€ app.py                # AplicaÃ§Ã£o principal FastAPI
â”œâ”€â”€ Dockerfile            # InstruÃ§Ãµes para build da imagem Docker
â”œâ”€â”€ docker-compose.yml    # ConfiguraÃ§Ã£o de mÃºltiplos serviÃ§os
â””â”€â”€ requirements.txt      # DependÃªncias Python
```

## PrÃ©-requisitos

- Docker
- Docker Compose

## Como Executar

1. Clone o repositÃ³rio:

```bash
git clone <url-do-repositorio>
cd <diretorio-do-projeto>
```

2. Inicie o serviÃ§o com Docker Compose:

```bash
docker-compose up --build
```

Isso iniciarÃ¡ uma instÃ¢ncia da aplicaÃ§Ã£o:
- `app-a` - acessÃ­vel em http://localhost:8000

## Testando a AplicaÃ§Ã£o

### Verificar o status do serviÃ§o:

```bash
curl http://localhost:8000/
```

VocÃª deverÃ¡ receber uma resposta como:
```json
{"message": "Esse Ã© o serviÃ§o app-a"}
```

### Enviar uma requisiÃ§Ã£o de processamento:

```bash
curl -X POST http://localhost:8000/process \
  -H "Content-Type: application/json" \
  -d '["dado-inicial"]'
```

## ConfiguraÃ§Ã£o

O arquivo `docker-compose.yml` estÃ¡ configurado inicialmente para executar apenas o serviÃ§o `app-a`. VocÃª pode descomentar as seÃ§Ãµes dos serviÃ§os `app-b` e `app-c`, bem como as variÃ¡veis de ambiente adicionais, para criar um ambiente distribuÃ­do mais complexo.

```yaml
version: '3.8'

services:
  app-a:
    build: .
    ports:
      - "8000:8000"
    environment:
      - APP_NAME=app-a
      # - APP_URL_DESTINO=http://app-b:8000
      # - APP_ERRORS=5
      # - APP_LATENCY=100
    networks:
      - app-network

  # app-b:
  #   build: .
  #   ports:
  #     - "8001:8000"
  #   environment:
  #     - APP_NAME=app-b
  #     - APP_URL_DESTINO=http://app-c:8000
  #     - APP_ERRORS=10
  #     - APP_LATENCY=150
  #   networks:
  #     - app-network

  # app-c:
  #   build: .
  #   ports:
  #     - "8002:8000"
  #   environment:
  #     - APP_NAME=app-c
  #     - APP_ERRORS=15
  #     - APP_LATENCY=200
  #   networks:
  #     - app-network

networks:
  app-network:
```

VocÃª pode personalizar o comportamento dos serviÃ§os modificando as variÃ¡veis de ambiente:

- `APP_NAME`: Nome do serviÃ§o
- `APP_URL_DESTINO`: URL para qual o serviÃ§o deve propagar a requisiÃ§Ã£o
- `APP_ERRORS`: Porcentagem de requisiÃ§Ãµes que resultarÃ£o em erro (0-100)
- `APP_LATENCY`: LatÃªncia mÃ¡xima em milissegundos (atraso aleatÃ³rio entre 0 e esse valor)